{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2285c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ed3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = VOCSegmentation(root='data/', year='2012', image_set='train', download=True)\n",
    "\n",
    "# writing custom dataset, inheriting from VOCSegmentation dataset\n",
    "class VOCSegmentationWithPIL(VOCSegmentation):\n",
    "    def __init__(self, root='data', year='2012', image_set='train',\n",
    "                 download=True, image_size=(224, 224)):\n",
    "        super().__init__(root=root, year=year, image_set=image_set, download=download)\n",
    "        self.image_resize = T.Resize(image_size)\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(image_size, interpolation=Image.NEAREST),\n",
    "            T.PILToTensor(),  # Keeps label values intact\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = super().__getitem__(index)\n",
    "        image = self.image_resize(image)  # still PIL.Image\n",
    "        mask = self.mask_transform(mask).squeeze(0).long()  # [H, W] as LongTensor\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aace71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_pil(batch):\n",
    "    images, masks = zip(*batch)  # tuple of lists\n",
    "    return list(images), torch.stack(masks)  # keep images as list of PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9259d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: src/data_train/VOCtrainval_11-May-2012.tar\n",
      "Extracting src/data_train/VOCtrainval_11-May-2012.tar to src/data_train\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VOCSegmentationWithPIL(\n",
    "    root='src/data_train',\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    download=True,\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn_pil,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c5e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: src/data_val/VOCtrainval_11-May-2012.tar\n",
      "Extracting src/data_val/VOCtrainval_11-May-2012.tar to src/data_val\n"
     ]
    }
   ],
   "source": [
    "val_dataset = VOCSegmentationWithPIL(\n",
    "    root='src/data_val',\n",
    "    year='2012',\n",
    "    image_set='val',\n",
    "    download=True,\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn_pil,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=1024, num_classes=21):\n",
    "        super().__init__()\n",
    "\n",
    "        # Upsample from 16x16 -> 32x32 -> 64x64 -> 128x128 -> 224x224\n",
    "        self.up1 = self._upsample_block(in_channels, 512)\n",
    "        self.up2 = self._upsample_block(512, 256)\n",
    "        self.up3 = self._upsample_block(256, 128)\n",
    "        self.up4 = self._upsample_block(128, 64)\n",
    "\n",
    "        # Skip connections\n",
    "        self.skip_32 = nn.Conv2d(in_channels, 512, kernel_size=1)\n",
    "        self.skip_64 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.skip_128 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "\n",
    "        # Final prediction layer\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "        # Auxiliary outputs (for deeper supervision)\n",
    "        self.aux1_conv = nn.Conv2d(128, num_classes, kernel_size=1)  # from x3\n",
    "        self.aux2_conv = nn.Conv2d(64, num_classes, kernel_size=1)   # from x4    \n",
    "    \n",
    "    def _upsample_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2)  # just Added dropout to regularize because it was observed after 20 epoch it was overfitting\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1024, 16, 16]\n",
    "\n",
    "        x1 = self.up1(x)  # 16 -> 32\n",
    "        skip_32 = F.interpolate(self.skip_32(x), size=x1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x1 = x1 + skip_32\n",
    "\n",
    "        x2 = self.up2(x1)  # 32 -> 64\n",
    "        skip_64 = F.interpolate(self.skip_64(x1), size=x2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x2 = x2 + skip_64\n",
    "\n",
    "        x3 = self.up3(x2)  # 64 -> 128\n",
    "        skip_128 = F.interpolate(self.skip_128(x2), size=x3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x3 = x3 + skip_128\n",
    "\n",
    "        x4 = self.up4(x3)  # 128 -> 256\n",
    "\n",
    "        # Main output\n",
    "        x_out = F.interpolate(x4, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        x_out = self.final_conv(x_out)\n",
    "\n",
    "        # Auxiliary outputs\n",
    "        aux1 = F.interpolate(self.aux1_conv(x3), size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        aux2 = F.interpolate(self.aux2_conv(x4), size=(224, 224), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return x_out, aux1, aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2124208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, Dinov2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168e5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoSegModel(nn.Module):\n",
    "    def __init__(self, freeze_dino=True, num_classes=21):\n",
    "        super().__init__()\n",
    "        self.dino = Dinov2Model.from_pretrained(\"facebook/dinov2-large\")\n",
    "        self.decoder = UNetDecoder(in_channels=1024, num_classes=num_classes)\n",
    "        \n",
    "\n",
    "        if freeze_dino:\n",
    "            # Step 1: Freeze all\n",
    "            for param in self.dino.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Step 2: Unfreeze layers 18-23 explicitly\n",
    "            for i in range(22, 24):\n",
    "                for name, param in self.dino.named_parameters():\n",
    "                    if f\"encoder.layer.{i}.\" in name:\n",
    "                        param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, pixel_values):  # Input: [B, 3, 224, 224]\n",
    "        feats = self.dino(pixel_values).last_hidden_state  # [B, 257, 1024]\n",
    "        feats = feats[:, 1:, :]  # remove CLS token\n",
    "        feats = feats.reshape(-1, 16, 16, 1024).permute(0, 3, 1, 2)  # [B, 1024, 16, 16]\n",
    "\n",
    "        x_out, aux1, aux2 = self.decoder(feats)\n",
    "        #x_out = self.decoder(feats)\n",
    "        return x_out, aux1, aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853c6ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 19, 224, 224]),\n",
       " torch.Size([8, 19, 224, 224]),\n",
       " torch.Size([8, 19, 224, 224]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(8, 3, 224, 224)\n",
    "model = DinoSegModel(freeze_dino=True, num_classes=19)\n",
    "op, ax1, ax2 = model(rand)\n",
    "op.shape, ax1.shape, ax2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8527f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen: dino.embeddings.cls_token\n",
      "Frozen: dino.embeddings.mask_token\n",
      "Frozen: dino.embeddings.position_embeddings\n",
      "Frozen: dino.embeddings.patch_embeddings.projection.weight\n",
      "Frozen: dino.embeddings.patch_embeddings.projection.bias\n",
      "Frozen: dino.encoder.layer.0.norm1.weight\n",
      "Frozen: dino.encoder.layer.0.norm1.bias\n",
      "Frozen: dino.encoder.layer.0.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.0.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.0.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.0.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.0.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.0.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.0.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.0.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.0.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.0.norm2.weight\n",
      "Frozen: dino.encoder.layer.0.norm2.bias\n",
      "Frozen: dino.encoder.layer.0.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.0.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.0.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.0.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.0.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.1.norm1.weight\n",
      "Frozen: dino.encoder.layer.1.norm1.bias\n",
      "Frozen: dino.encoder.layer.1.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.1.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.1.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.1.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.1.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.1.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.1.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.1.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.1.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.1.norm2.weight\n",
      "Frozen: dino.encoder.layer.1.norm2.bias\n",
      "Frozen: dino.encoder.layer.1.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.1.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.1.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.1.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.1.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.2.norm1.weight\n",
      "Frozen: dino.encoder.layer.2.norm1.bias\n",
      "Frozen: dino.encoder.layer.2.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.2.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.2.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.2.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.2.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.2.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.2.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.2.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.2.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.2.norm2.weight\n",
      "Frozen: dino.encoder.layer.2.norm2.bias\n",
      "Frozen: dino.encoder.layer.2.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.2.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.2.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.2.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.2.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.3.norm1.weight\n",
      "Frozen: dino.encoder.layer.3.norm1.bias\n",
      "Frozen: dino.encoder.layer.3.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.3.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.3.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.3.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.3.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.3.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.3.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.3.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.3.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.3.norm2.weight\n",
      "Frozen: dino.encoder.layer.3.norm2.bias\n",
      "Frozen: dino.encoder.layer.3.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.3.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.3.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.3.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.3.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.4.norm1.weight\n",
      "Frozen: dino.encoder.layer.4.norm1.bias\n",
      "Frozen: dino.encoder.layer.4.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.4.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.4.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.4.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.4.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.4.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.4.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.4.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.4.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.4.norm2.weight\n",
      "Frozen: dino.encoder.layer.4.norm2.bias\n",
      "Frozen: dino.encoder.layer.4.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.4.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.4.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.4.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.4.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.5.norm1.weight\n",
      "Frozen: dino.encoder.layer.5.norm1.bias\n",
      "Frozen: dino.encoder.layer.5.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.5.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.5.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.5.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.5.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.5.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.5.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.5.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.5.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.5.norm2.weight\n",
      "Frozen: dino.encoder.layer.5.norm2.bias\n",
      "Frozen: dino.encoder.layer.5.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.5.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.5.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.5.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.5.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.6.norm1.weight\n",
      "Frozen: dino.encoder.layer.6.norm1.bias\n",
      "Frozen: dino.encoder.layer.6.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.6.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.6.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.6.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.6.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.6.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.6.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.6.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.6.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.6.norm2.weight\n",
      "Frozen: dino.encoder.layer.6.norm2.bias\n",
      "Frozen: dino.encoder.layer.6.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.6.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.6.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.6.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.6.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.7.norm1.weight\n",
      "Frozen: dino.encoder.layer.7.norm1.bias\n",
      "Frozen: dino.encoder.layer.7.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.7.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.7.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.7.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.7.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.7.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.7.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.7.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.7.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.7.norm2.weight\n",
      "Frozen: dino.encoder.layer.7.norm2.bias\n",
      "Frozen: dino.encoder.layer.7.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.7.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.7.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.7.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.7.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.8.norm1.weight\n",
      "Frozen: dino.encoder.layer.8.norm1.bias\n",
      "Frozen: dino.encoder.layer.8.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.8.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.8.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.8.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.8.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.8.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.8.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.8.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.8.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.8.norm2.weight\n",
      "Frozen: dino.encoder.layer.8.norm2.bias\n",
      "Frozen: dino.encoder.layer.8.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.8.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.8.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.8.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.8.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.9.norm1.weight\n",
      "Frozen: dino.encoder.layer.9.norm1.bias\n",
      "Frozen: dino.encoder.layer.9.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.9.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.9.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.9.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.9.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.9.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.9.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.9.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.9.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.9.norm2.weight\n",
      "Frozen: dino.encoder.layer.9.norm2.bias\n",
      "Frozen: dino.encoder.layer.9.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.9.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.9.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.9.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.9.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.10.norm1.weight\n",
      "Frozen: dino.encoder.layer.10.norm1.bias\n",
      "Frozen: dino.encoder.layer.10.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.10.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.10.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.10.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.10.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.10.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.10.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.10.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.10.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.10.norm2.weight\n",
      "Frozen: dino.encoder.layer.10.norm2.bias\n",
      "Frozen: dino.encoder.layer.10.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.10.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.10.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.10.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.10.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.11.norm1.weight\n",
      "Frozen: dino.encoder.layer.11.norm1.bias\n",
      "Frozen: dino.encoder.layer.11.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.11.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.11.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.11.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.11.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.11.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.11.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.11.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.11.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.11.norm2.weight\n",
      "Frozen: dino.encoder.layer.11.norm2.bias\n",
      "Frozen: dino.encoder.layer.11.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.11.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.11.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.11.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.11.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.12.norm1.weight\n",
      "Frozen: dino.encoder.layer.12.norm1.bias\n",
      "Frozen: dino.encoder.layer.12.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.12.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.12.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.12.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.12.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.12.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.12.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.12.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.12.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.12.norm2.weight\n",
      "Frozen: dino.encoder.layer.12.norm2.bias\n",
      "Frozen: dino.encoder.layer.12.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.12.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.12.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.12.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.12.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.13.norm1.weight\n",
      "Frozen: dino.encoder.layer.13.norm1.bias\n",
      "Frozen: dino.encoder.layer.13.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.13.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.13.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.13.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.13.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.13.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.13.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.13.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.13.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.13.norm2.weight\n",
      "Frozen: dino.encoder.layer.13.norm2.bias\n",
      "Frozen: dino.encoder.layer.13.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.13.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.13.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.13.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.13.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.14.norm1.weight\n",
      "Frozen: dino.encoder.layer.14.norm1.bias\n",
      "Frozen: dino.encoder.layer.14.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.14.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.14.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.14.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.14.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.14.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.14.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.14.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.14.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.14.norm2.weight\n",
      "Frozen: dino.encoder.layer.14.norm2.bias\n",
      "Frozen: dino.encoder.layer.14.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.14.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.14.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.14.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.14.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.15.norm1.weight\n",
      "Frozen: dino.encoder.layer.15.norm1.bias\n",
      "Frozen: dino.encoder.layer.15.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.15.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.15.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.15.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.15.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.15.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.15.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.15.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.15.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.15.norm2.weight\n",
      "Frozen: dino.encoder.layer.15.norm2.bias\n",
      "Frozen: dino.encoder.layer.15.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.15.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.15.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.15.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.15.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.16.norm1.weight\n",
      "Frozen: dino.encoder.layer.16.norm1.bias\n",
      "Frozen: dino.encoder.layer.16.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.16.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.16.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.16.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.16.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.16.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.16.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.16.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.16.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.16.norm2.weight\n",
      "Frozen: dino.encoder.layer.16.norm2.bias\n",
      "Frozen: dino.encoder.layer.16.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.16.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.16.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.16.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.16.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.17.norm1.weight\n",
      "Frozen: dino.encoder.layer.17.norm1.bias\n",
      "Frozen: dino.encoder.layer.17.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.17.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.17.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.17.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.17.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.17.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.17.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.17.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.17.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.17.norm2.weight\n",
      "Frozen: dino.encoder.layer.17.norm2.bias\n",
      "Frozen: dino.encoder.layer.17.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.17.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.17.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.17.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.17.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.18.norm1.weight\n",
      "Frozen: dino.encoder.layer.18.norm1.bias\n",
      "Frozen: dino.encoder.layer.18.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.18.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.18.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.18.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.18.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.18.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.18.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.18.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.18.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.18.norm2.weight\n",
      "Frozen: dino.encoder.layer.18.norm2.bias\n",
      "Frozen: dino.encoder.layer.18.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.18.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.18.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.18.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.18.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.19.norm1.weight\n",
      "Frozen: dino.encoder.layer.19.norm1.bias\n",
      "Frozen: dino.encoder.layer.19.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.19.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.19.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.19.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.19.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.19.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.19.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.19.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.19.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.19.norm2.weight\n",
      "Frozen: dino.encoder.layer.19.norm2.bias\n",
      "Frozen: dino.encoder.layer.19.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.19.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.19.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.19.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.19.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.20.norm1.weight\n",
      "Frozen: dino.encoder.layer.20.norm1.bias\n",
      "Frozen: dino.encoder.layer.20.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.20.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.20.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.20.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.20.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.20.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.20.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.20.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.20.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.20.norm2.weight\n",
      "Frozen: dino.encoder.layer.20.norm2.bias\n",
      "Frozen: dino.encoder.layer.20.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.20.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.20.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.20.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.20.layer_scale2.lambda1\n",
      "Frozen: dino.encoder.layer.21.norm1.weight\n",
      "Frozen: dino.encoder.layer.21.norm1.bias\n",
      "Frozen: dino.encoder.layer.21.attention.attention.query.weight\n",
      "Frozen: dino.encoder.layer.21.attention.attention.query.bias\n",
      "Frozen: dino.encoder.layer.21.attention.attention.key.weight\n",
      "Frozen: dino.encoder.layer.21.attention.attention.key.bias\n",
      "Frozen: dino.encoder.layer.21.attention.attention.value.weight\n",
      "Frozen: dino.encoder.layer.21.attention.attention.value.bias\n",
      "Frozen: dino.encoder.layer.21.attention.output.dense.weight\n",
      "Frozen: dino.encoder.layer.21.attention.output.dense.bias\n",
      "Frozen: dino.encoder.layer.21.layer_scale1.lambda1\n",
      "Frozen: dino.encoder.layer.21.norm2.weight\n",
      "Frozen: dino.encoder.layer.21.norm2.bias\n",
      "Frozen: dino.encoder.layer.21.mlp.fc1.weight\n",
      "Frozen: dino.encoder.layer.21.mlp.fc1.bias\n",
      "Frozen: dino.encoder.layer.21.mlp.fc2.weight\n",
      "Frozen: dino.encoder.layer.21.mlp.fc2.bias\n",
      "Frozen: dino.encoder.layer.21.layer_scale2.lambda1\n",
      "Trainable: dino.encoder.layer.22.norm1.weight\n",
      "Trainable: dino.encoder.layer.22.norm1.bias\n",
      "Trainable: dino.encoder.layer.22.attention.attention.query.weight\n",
      "Trainable: dino.encoder.layer.22.attention.attention.query.bias\n",
      "Trainable: dino.encoder.layer.22.attention.attention.key.weight\n",
      "Trainable: dino.encoder.layer.22.attention.attention.key.bias\n",
      "Trainable: dino.encoder.layer.22.attention.attention.value.weight\n",
      "Trainable: dino.encoder.layer.22.attention.attention.value.bias\n",
      "Trainable: dino.encoder.layer.22.attention.output.dense.weight\n",
      "Trainable: dino.encoder.layer.22.attention.output.dense.bias\n",
      "Trainable: dino.encoder.layer.22.layer_scale1.lambda1\n",
      "Trainable: dino.encoder.layer.22.norm2.weight\n",
      "Trainable: dino.encoder.layer.22.norm2.bias\n",
      "Trainable: dino.encoder.layer.22.mlp.fc1.weight\n",
      "Trainable: dino.encoder.layer.22.mlp.fc1.bias\n",
      "Trainable: dino.encoder.layer.22.mlp.fc2.weight\n",
      "Trainable: dino.encoder.layer.22.mlp.fc2.bias\n",
      "Trainable: dino.encoder.layer.22.layer_scale2.lambda1\n",
      "Trainable: dino.encoder.layer.23.norm1.weight\n",
      "Trainable: dino.encoder.layer.23.norm1.bias\n",
      "Trainable: dino.encoder.layer.23.attention.attention.query.weight\n",
      "Trainable: dino.encoder.layer.23.attention.attention.query.bias\n",
      "Trainable: dino.encoder.layer.23.attention.attention.key.weight\n",
      "Trainable: dino.encoder.layer.23.attention.attention.key.bias\n",
      "Trainable: dino.encoder.layer.23.attention.attention.value.weight\n",
      "Trainable: dino.encoder.layer.23.attention.attention.value.bias\n",
      "Trainable: dino.encoder.layer.23.attention.output.dense.weight\n",
      "Trainable: dino.encoder.layer.23.attention.output.dense.bias\n",
      "Trainable: dino.encoder.layer.23.layer_scale1.lambda1\n",
      "Trainable: dino.encoder.layer.23.norm2.weight\n",
      "Trainable: dino.encoder.layer.23.norm2.bias\n",
      "Trainable: dino.encoder.layer.23.mlp.fc1.weight\n",
      "Trainable: dino.encoder.layer.23.mlp.fc1.bias\n",
      "Trainable: dino.encoder.layer.23.mlp.fc2.weight\n",
      "Trainable: dino.encoder.layer.23.mlp.fc2.bias\n",
      "Trainable: dino.encoder.layer.23.layer_scale2.lambda1\n",
      "Frozen: dino.layernorm.weight\n",
      "Frozen: dino.layernorm.bias\n",
      "Trainable: decoder.up1.1.weight\n",
      "Trainable: decoder.up1.1.bias\n",
      "Trainable: decoder.up1.2.weight\n",
      "Trainable: decoder.up1.2.bias\n",
      "Trainable: decoder.up2.1.weight\n",
      "Trainable: decoder.up2.1.bias\n",
      "Trainable: decoder.up2.2.weight\n",
      "Trainable: decoder.up2.2.bias\n",
      "Trainable: decoder.up3.1.weight\n",
      "Trainable: decoder.up3.1.bias\n",
      "Trainable: decoder.up3.2.weight\n",
      "Trainable: decoder.up3.2.bias\n",
      "Trainable: decoder.up4.1.weight\n",
      "Trainable: decoder.up4.1.bias\n",
      "Trainable: decoder.up4.2.weight\n",
      "Trainable: decoder.up4.2.bias\n",
      "Trainable: decoder.skip_32.weight\n",
      "Trainable: decoder.skip_32.bias\n",
      "Trainable: decoder.skip_64.weight\n",
      "Trainable: decoder.skip_64.bias\n",
      "Trainable: decoder.skip_128.weight\n",
      "Trainable: decoder.skip_128.bias\n",
      "Trainable: decoder.final_conv.weight\n",
      "Trainable: decoder.final_conv.bias\n",
      "Trainable: decoder.aux1_conv.weight\n",
      "Trainable: decoder.aux1_conv.bias\n",
      "Trainable: decoder.aux2_conv.weight\n",
      "Trainable: decoder.aux2_conv.bias\n"
     ]
    }
   ],
   "source": [
    "# model = DinoSegModel()\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Trainable: {name}\")\n",
    "    else:\n",
    "        print(f\"Frozen: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from transformers import Dinov2Model\n",
    "\n",
    "\n",
    "# class SimplePixelDecoder(nn.Module):\n",
    "#     \"\"\"\n",
    "#     A simplified version of Mask2Former's pixel decoder.\n",
    "#     Converts DINO features into multi-scale features for the transformer decoder.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, in_channels=1024, embed_dim=256):\n",
    "#         super().__init__()\n",
    "#         self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=1)\n",
    "#         self.out_norm = nn.BatchNorm2d(embed_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [B, 1024, 16, 16] -> [B, 256, 16, 16]\n",
    "#         x = self.proj(x)\n",
    "#         x = self.out_norm(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class TransformerDecoder(nn.Module):\n",
    "#     \"\"\"\n",
    "#     A simplified transformer decoder for segmentation.\n",
    "#     Inspired by Mask2Former: takes features and learns query embeddings to predict masks.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, embed_dim=256, num_queries=100, num_classes=21):\n",
    "#         super().__init__()\n",
    "#         self.query_embed = nn.Embedding(num_queries, embed_dim)\n",
    "#         self.transformer_decoder_layer = nn.TransformerDecoderLayer(embed_dim, nhead=8, dim_feedforward=1024)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(self.transformer_decoder_layer, num_layers=6)\n",
    "#         self.class_embed = nn.Linear(embed_dim, num_classes)\n",
    "#         self.mask_embed = nn.Sequential(\n",
    "#             nn.Linear(embed_dim, embed_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(embed_dim, embed_dim)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [B, C, H, W] -> [B, HW, C]\n",
    "#         B, C, H, W = x.shape\n",
    "#         x_flat = x.flatten(2).permute(2, 0, 1)  # [HW, B, C]\n",
    "#         query_embed = self.query_embed.weight.unsqueeze(1).repeat(1, B, 1)  # [num_queries, B, C]\n",
    "\n",
    "#         tgt = torch.zeros_like(query_embed)  # [num_queries, B, C]\n",
    "#         hs = self.transformer_decoder(tgt, x_flat)  # [num_queries, B, C]\n",
    "\n",
    "#         hs = hs.transpose(0, 1)  # [B, num_queries, C]\n",
    "#         class_logits = self.class_embed(hs)  # [B, num_queries, num_classes]\n",
    "#         mask_embed = self.mask_embed(hs)  # [B, num_queries, C]\n",
    "\n",
    "#         # Predict masks: linear projection to per-pixel mask logits\n",
    "#         masks = torch.einsum(\"bqc, bchw -> bqhw\", mask_embed, x)\n",
    "\n",
    "#         return class_logits, masks\n",
    "\n",
    "\n",
    "# class DINO_Mask2Former_Segmentation(nn.Module):\n",
    "#     def __init__(self, num_classes=21, freeze_dino=True):\n",
    "#         super().__init__()\n",
    "#         self.dino = Dinov2Model.from_pretrained(\"facebook/dinov2-large\")\n",
    "#         self.pixel_decoder = SimplePixelDecoder(in_channels=1024, embed_dim=256)\n",
    "#         self.transformer_decoder = TransformerDecoder(embed_dim=256, num_queries=100, num_classes=num_classes)\n",
    "\n",
    "#         if freeze_dino:\n",
    "#             for param in self.dino.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             for name, param in self.dino.named_parameters():\n",
    "#                 if any(f\"blocks.{i}\" in name for i in range(18, 24)):\n",
    "#                     param.requires_grad = True\n",
    "\n",
    "#     def forward(self, pixel_values):\n",
    "#         # pixel_values: [B, 3, 224, 224]\n",
    "#         feats = self.dino(pixel_values).last_hidden_state  # [B, 257, 1024]\n",
    "#         feats = feats[:, 1:, :].reshape(-1, 16, 16, 1024).permute(0, 3, 1, 2)  # [B, 1024, 16, 16]\n",
    "\n",
    "#         pixel_feats = self.pixel_decoder(feats)  # [B, 256, 16, 16]\n",
    "#         class_logits, masks = self.transformer_decoder(pixel_feats)  # logits: [B, Q, C], masks: [B, Q, H, W]\n",
    "\n",
    "#         return {\n",
    "#             \"class_logits\": class_logits,  # For classification loss (cross-entropy)\n",
    "#             \"masks\": masks                # For mask loss (e.g., BCE or dice)\n",
    "#         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0208f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a94f3b",
   "metadata": {},
   "source": [
    "### With checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb758271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.lovasz_losses import lovasz_softmax\n",
    "# def hybrid_loss_fn(logits, target, ignore_index=255):\n",
    "#     ce = F.cross_entropy(logits, target, ignore_index=ignore_index)\n",
    "#     lv = lovasz_softmax(logits, target, ignore=ignore_index)\n",
    "#     return ce + lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ed5c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from checkpoint at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 183/183 [00:27<00:00,  6.57it/s, loss=0.036] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 183/183 [00:27<00:00,  6.56it/s, loss=0.0593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 183/183 [00:27<00:00,  6.56it/s, loss=0.137] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 183/183 [00:27<00:00,  6.57it/s, loss=0.0862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 183/183 [00:27<00:00,  6.57it/s, loss=0.0931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 183/183 [00:27<00:00,  6.54it/s, loss=0.0643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 183/183 [00:28<00:00,  6.52it/s, loss=0.0592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 183/183 [00:28<00:00,  6.52it/s, loss=0.0779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 183/183 [00:28<00:00,  6.53it/s, loss=0.0394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 183/183 [00:28<00:00,  6.50it/s, loss=0.049] \n",
      "Validation Epoch 40: 100%|██████████| 182/182 [00:25<00:00,  7.08it/s, val_loss=0.0458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.0641 | Val Loss: 0.2968 | Val mIoU: 0.8275\n",
      "Checkpoint saved at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 183/183 [00:28<00:00,  6.51it/s, loss=0.0432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 183/183 [00:28<00:00,  6.51it/s, loss=0.0459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 183/183 [00:28<00:00,  6.54it/s, loss=0.0373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 183/183 [00:28<00:00,  6.54it/s, loss=0.0754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 183/183 [00:28<00:00,  6.54it/s, loss=0.0425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 183/183 [00:28<00:00,  6.53it/s, loss=0.0246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 183/183 [00:28<00:00,  6.53it/s, loss=0.19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 183/183 [00:28<00:00,  6.53it/s, loss=0.0943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 183/183 [00:28<00:00,  6.51it/s, loss=0.0232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 183/183 [00:28<00:00,  6.50it/s, loss=0.029] \n",
      "Validation Epoch 50: 100%|██████████| 182/182 [00:25<00:00,  7.09it/s, val_loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.0484 | Val Loss: 0.2915 | Val mIoU: 0.8329\n",
      "Checkpoint saved at epoch 50\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ------------------ Setup ------------------\n",
    "num_classes = 21\n",
    "ignore_index = 255\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "model = DinoSegModel(freeze_dino=True).to(device)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-large\")\n",
    "\n",
    "# Loss, Optimizer, Scheduler\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "\n",
    "# from src.lovasz_losses import lovasz_softmax\n",
    "# def lovasz_loss_fn(logits, targets):\n",
    "#     return lovasz_softmax(logits, targets, ignore=255)\n",
    "# criterion = lovasz_loss_fn\n",
    "\n",
    "#criterion = hybrid_loss_fn\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# Metric\n",
    "miou_metric = MulticlassJaccardIndex(num_classes=num_classes, ignore_index=ignore_index).to(device)\n",
    "\n",
    "# Training config\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, val_ious = [], [], []\n",
    "\n",
    "# Paths\n",
    "best_model_path = \"best_model.pth\"\n",
    "checkpoint_path = \"last_checkpoint.pth\"\n",
    "best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "# ------------------ Load from Checkpoint (if exists) ------------------\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    print(f\"Resumed training from checkpoint at epoch {start_epoch}\")\n",
    "\n",
    "# ------------------ Validation ------------------\n",
    "def evaluate(model, loader, criterion, image_processor, device, epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    miou_metric.reset()\n",
    "    save_dir = os.path.join(\"val_preds_kitto\", f\"epoch_{epoch+1}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loop = tqdm(loader, desc=f\"Validation Epoch {epoch+1}\")\n",
    "        for step, (images, masks) in enumerate(val_loop):\n",
    "            #inputs = image_processor(images, return_tensors='pt').to(device)\n",
    "\n",
    "            inputs = torch.stack([T.ToTensor()(img) for img in images]).to(device)\n",
    "            inputs = T.Normalize(mean=[0.5]*3, std=[0.5]*3)(inputs)\n",
    "\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            #outputs, _, _ = model(inputs.pixel_values)\n",
    "            # outputs, _, _ = model(inputs)\n",
    "            # loss = criterion(outputs, masks)\n",
    "            \n",
    "            #out, aux1, aux2 = model(inputs.pixel_values) # if using AutoImageProcessor of DINO\n",
    "            out, aux1, aux2 = model(inputs)\n",
    "            main_loss = criterion(out, masks)\n",
    "            aux_loss1 = criterion(aux1, F.interpolate(masks.unsqueeze(1).float(), size=aux1.shape[2:], mode='nearest').squeeze(1).long())\n",
    "            aux_loss2 = criterion(aux2, F.interpolate(masks.unsqueeze(1).float(), size=aux2.shape[2:], mode='nearest').squeeze(1).long())\n",
    "            loss = main_loss + 0.4 * aux_loss1 + 0.4 * aux_loss2\n",
    "        \n",
    "            val_loss += loss.item()\n",
    "            val_loop.set_postfix(val_loss=loss.item())\n",
    "\n",
    "            #preds = outputs.argmax(dim=1)\n",
    "            preds = out.argmax(dim=1)\n",
    "            miou_metric.update(preds, masks)\n",
    "\n",
    "            # Save every sample in the batch\n",
    "            for i in range(len(images)):\n",
    "                #image_np = images[i]\n",
    "                mask_np = masks[i].cpu().numpy()\n",
    "                pred_np = preds[i].cpu().numpy()\n",
    "\n",
    "                #plt.imsave(os.path.join(save_dir, f\"image_{step}_{i}.jpg\"), image_np)\n",
    "                plt.imsave(os.path.join(save_dir, f\"gt_{step}_{i}.png\"), mask_np, cmap='nipy_spectral')\n",
    "                plt.imsave(os.path.join(save_dir, f\"pred_{step}_{i}.png\"), pred_np, cmap='nipy_spectral')\n",
    "\n",
    "    return val_loss / len(loader), miou_metric.compute().item()\n",
    "\n",
    "# ------------------ Training Loop ------------------\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for images, masks in loop:\n",
    "        #inputs = image_processor(images, return_tensors='pt').to(device)\n",
    "        \n",
    "        inputs = torch.stack([T.ToTensor()(img) for img in images]).to(device)\n",
    "        inputs = T.Normalize(mean=[0.5]*3, std=[0.5]*3)(inputs)\n",
    "        \n",
    "        masks = masks.to(device)\n",
    "\n",
    "        #outputs, _, _ = model(inputs.pixel_values)\n",
    "        # outputs, _, _ = model(inputs)\n",
    "        # loss = criterion(outputs, masks)\n",
    "        \n",
    "        #out, aux1, aux2 = model(inputs.pixel_values)\n",
    "        out, aux1, aux2 = model(inputs)\n",
    "        main_loss = criterion(out, masks)\n",
    "        aux_loss1 = criterion(aux1, F.interpolate(masks.unsqueeze(1).float(), size=aux1.shape[2:], mode='nearest').squeeze(1).long())\n",
    "        aux_loss2 = criterion(aux2, F.interpolate(masks.unsqueeze(1).float(), size=aux2.shape[2:], mode='nearest').squeeze(1).long())\n",
    "        loss = main_loss + 0.4 * aux_loss1 + 0.4 * aux_loss2\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Evaluate only every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_val_loss, val_miou = evaluate(model, val_loader, criterion, image_processor, device, epoch)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_ious.append(val_miou)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val mIoU: {val_miou:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Saved best model at epoch {epoch+1} with val loss {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        val_losses.append(None)\n",
    "        val_ious.append(None)\n",
    "\n",
    "    # Save checkpoint every epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef69bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchinfo import summary\n",
    "\n",
    "# Print the model architecture and parameter summary\n",
    "#summary(model, input_size=(1, 3, 224, 224), device=device.type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d50b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "# out, _, _ = model(dummy_input)\n",
    "\n",
    "# make_dot(out, params=dict(model.named_parameters())).render(\"model_graph\", format=\"png\")\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name}: requires_grad={param.requires_grad}, shape={param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a926ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8e29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e2734d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class KITTISegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, image_size=(224, 224)):\n",
    "        self.image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.png') or fname.endswith('.jpg')])\n",
    "        self.mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir) if fname.endswith('.png')])\n",
    "\n",
    "        self.image_transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "        \n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(image_size, interpolation=Image.NEAREST),\n",
    "            T.PILToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx])  # Assumes masks are already in correct class format\n",
    "        return self.image_transform(image), self.mask_transform(mask).squeeze(0).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_dataset = KITTISegmentationDataset(\n",
    "    image_dir='kitti_data/training/image_2',\n",
    "    mask_dir='kitti_data/training/semantic',\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "\n",
    "kitti_loader = DataLoader(\n",
    "    kitti_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c19fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DinoSegModel(\n",
       "  (dino): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): UNetDecoder(\n",
       "    (up1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up3): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up4): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (skip_32): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (skip_64): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (skip_128): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_conv): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (aux1_conv): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (aux2_conv): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = DinoSegModel(freeze_dino=True, num_classes=21).to(device)\n",
    "#model.load_state_dict(torch.load(\"/home/iiitb/Desktop/anant/playground/ProjectBytes/best_model.pth\", map_location=device))\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe657010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for images, masks in kitti_loader:\n",
    "        # print(images.shape, masks.shape)\n",
    "        # print(\"Unique labels in masks:\", torch.unique(masks))\n",
    "        count += 1 \n",
    "        # if count ==100:\n",
    "        #         break\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b51cb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DinoSegModel(\n",
       "  (dino): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): UNetDecoder(\n",
       "    (up1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up3): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (up4): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Dropout2d(p=0.2, inplace=False)\n",
       "    )\n",
       "    (skip_32): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (skip_64): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (skip_128): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_conv): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (aux1_conv): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (aux2_conv): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c2f26d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5ae254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model trained on VOC\n",
    "model = DinoSegModel(freeze_dino=True).to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Replace final head (assume it's named `self.head`)\n",
    "# If it's DPT or Linear, adjust the naming accordingly.\n",
    "num_kitti_classes = 34\n",
    "#model.head[4] = nn.Conv2d(256, num_kitti_classes, kernel_size=1)\n",
    "model.decoder.final_conv = nn.Conv2d(64, 34, kernel_size=1)\n",
    "model.decoder.aux1_conv = nn.Conv2d(128, 34, kernel_size=1)\n",
    "model.decoder.aux2_conv = nn.Conv2d(64, 34, kernel_size=1)\n",
    "\n",
    "# Freeze all parameters first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze only the new classifier layers\n",
    "for layer in [model.decoder.final_conv, model.decoder.aux1_conv, model.decoder.aux2_conv]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf1c46cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dino.embeddings.cls_token - requires_grad: False\n",
      "dino.embeddings.mask_token - requires_grad: False\n",
      "dino.embeddings.position_embeddings - requires_grad: False\n",
      "dino.embeddings.patch_embeddings.projection.weight - requires_grad: False\n",
      "dino.embeddings.patch_embeddings.projection.bias - requires_grad: False\n",
      "dino.encoder.layer.0.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.0.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.0.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.0.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.0.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.0.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.0.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.0.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.0.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.0.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.0.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.0.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.0.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.1.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.1.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.1.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.1.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.1.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.1.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.1.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.1.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.1.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.1.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.1.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.1.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.1.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.2.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.2.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.2.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.2.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.2.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.2.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.2.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.2.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.2.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.2.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.2.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.2.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.2.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.3.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.3.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.3.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.3.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.3.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.3.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.3.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.3.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.3.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.3.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.3.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.3.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.3.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.4.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.4.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.4.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.4.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.4.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.4.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.4.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.4.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.4.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.4.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.4.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.4.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.4.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.5.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.5.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.5.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.5.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.5.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.5.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.5.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.5.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.5.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.5.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.5.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.5.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.5.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.6.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.6.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.6.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.6.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.6.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.6.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.6.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.6.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.6.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.6.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.6.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.6.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.6.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.7.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.7.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.7.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.7.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.7.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.7.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.7.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.7.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.7.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.7.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.7.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.7.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.7.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.8.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.8.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.8.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.8.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.8.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.8.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.8.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.8.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.8.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.8.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.8.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.8.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.8.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.9.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.9.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.9.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.9.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.9.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.9.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.9.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.9.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.9.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.9.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.9.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.9.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.9.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.10.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.10.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.10.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.10.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.10.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.10.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.10.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.10.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.10.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.10.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.10.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.10.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.10.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.11.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.11.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.11.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.11.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.11.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.11.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.11.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.11.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.11.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.11.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.11.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.11.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.11.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.12.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.12.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.12.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.12.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.12.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.12.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.12.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.12.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.12.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.12.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.12.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.12.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.12.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.13.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.13.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.13.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.13.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.13.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.13.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.13.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.13.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.13.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.13.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.13.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.13.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.13.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.14.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.14.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.14.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.14.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.14.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.14.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.14.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.14.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.14.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.14.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.14.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.14.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.14.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.15.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.15.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.15.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.15.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.15.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.15.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.15.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.15.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.15.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.15.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.15.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.15.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.15.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.16.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.16.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.16.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.16.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.16.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.16.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.16.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.16.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.16.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.16.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.16.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.16.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.16.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.17.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.17.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.17.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.17.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.17.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.17.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.17.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.17.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.17.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.17.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.17.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.17.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.17.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.18.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.18.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.18.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.18.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.18.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.18.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.18.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.18.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.18.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.18.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.18.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.18.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.18.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.19.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.19.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.19.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.19.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.19.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.19.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.19.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.19.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.19.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.19.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.19.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.19.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.19.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.20.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.20.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.20.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.20.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.20.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.20.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.20.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.20.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.20.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.20.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.20.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.20.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.20.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.21.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.21.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.21.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.21.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.21.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.21.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.21.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.21.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.21.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.21.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.21.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.21.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.21.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.22.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.22.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.22.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.22.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.22.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.22.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.22.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.22.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.22.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.22.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.22.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.22.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.22.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.23.norm1.weight - requires_grad: False\n",
      "dino.encoder.layer.23.norm1.bias - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.query.weight - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.query.bias - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.key.weight - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.key.bias - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.value.weight - requires_grad: False\n",
      "dino.encoder.layer.23.attention.attention.value.bias - requires_grad: False\n",
      "dino.encoder.layer.23.attention.output.dense.weight - requires_grad: False\n",
      "dino.encoder.layer.23.attention.output.dense.bias - requires_grad: False\n",
      "dino.encoder.layer.23.layer_scale1.lambda1 - requires_grad: False\n",
      "dino.encoder.layer.23.norm2.weight - requires_grad: False\n",
      "dino.encoder.layer.23.norm2.bias - requires_grad: False\n",
      "dino.encoder.layer.23.mlp.fc1.weight - requires_grad: False\n",
      "dino.encoder.layer.23.mlp.fc1.bias - requires_grad: False\n",
      "dino.encoder.layer.23.mlp.fc2.weight - requires_grad: False\n",
      "dino.encoder.layer.23.mlp.fc2.bias - requires_grad: False\n",
      "dino.encoder.layer.23.layer_scale2.lambda1 - requires_grad: False\n",
      "dino.layernorm.weight - requires_grad: False\n",
      "dino.layernorm.bias - requires_grad: False\n",
      "decoder.up1.1.weight - requires_grad: False\n",
      "decoder.up1.1.bias - requires_grad: False\n",
      "decoder.up1.2.weight - requires_grad: False\n",
      "decoder.up1.2.bias - requires_grad: False\n",
      "decoder.up2.1.weight - requires_grad: False\n",
      "decoder.up2.1.bias - requires_grad: False\n",
      "decoder.up2.2.weight - requires_grad: False\n",
      "decoder.up2.2.bias - requires_grad: False\n",
      "decoder.up3.1.weight - requires_grad: False\n",
      "decoder.up3.1.bias - requires_grad: False\n",
      "decoder.up3.2.weight - requires_grad: False\n",
      "decoder.up3.2.bias - requires_grad: False\n",
      "decoder.up4.1.weight - requires_grad: False\n",
      "decoder.up4.1.bias - requires_grad: False\n",
      "decoder.up4.2.weight - requires_grad: False\n",
      "decoder.up4.2.bias - requires_grad: False\n",
      "decoder.skip_32.weight - requires_grad: False\n",
      "decoder.skip_32.bias - requires_grad: False\n",
      "decoder.skip_64.weight - requires_grad: False\n",
      "decoder.skip_64.bias - requires_grad: False\n",
      "decoder.skip_128.weight - requires_grad: False\n",
      "decoder.skip_128.bias - requires_grad: False\n",
      "decoder.final_conv.weight - requires_grad: True\n",
      "decoder.final_conv.bias - requires_grad: True\n",
      "decoder.aux1_conv.weight - requires_grad: True\n",
      "decoder.aux1_conv.bias - requires_grad: True\n",
      "decoder.aux2_conv.weight - requires_grad: True\n",
      "decoder.aux2_conv.bias - requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# Confirm:\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} - requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c517d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 2: 100%|██████████| 25/25 [00:03<00:00,  8.27it/s, loss=2.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 3: 100%|██████████| 25/25 [00:03<00:00,  8.28it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 2.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 4: 100%|██████████| 25/25 [00:03<00:00,  8.18it/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 2.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 5: 100%|██████████| 25/25 [00:03<00:00,  8.18it/s, loss=2.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 2.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 6: 100%|██████████| 25/25 [00:03<00:00,  8.31it/s, loss=2.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 7: 100%|██████████| 25/25 [00:03<00:00,  8.25it/s, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.9709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 8: 100%|██████████| 25/25 [00:03<00:00,  8.26it/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 1.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 9: 100%|██████████| 25/25 [00:03<00:00,  8.26it/s, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 1.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 10: 100%|██████████| 25/25 [00:03<00:00,  8.23it/s, loss=2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 1.9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 11: 100%|██████████| 25/25 [00:03<00:00,  8.22it/s, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 1.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 12: 100%|██████████| 25/25 [00:03<00:00,  8.25it/s, loss=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 1.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 13: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s, loss=1.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 1.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 14: 100%|██████████| 25/25 [00:03<00:00,  8.29it/s, loss=2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 1.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 15: 100%|██████████| 25/25 [00:03<00:00,  8.23it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 1.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 16: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s, loss=1.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 1.9024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 17: 100%|██████████| 25/25 [00:03<00:00,  8.22it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 1.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 18: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 1.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 19: 100%|██████████| 25/25 [00:03<00:00,  8.27it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 1.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 20: 100%|██████████| 25/25 [00:03<00:00,  8.20it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 1.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 21: 100%|██████████| 25/25 [00:03<00:00,  8.29it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 1.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 22: 100%|██████████| 25/25 [00:03<00:00,  8.30it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 1.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 23: 100%|██████████| 25/25 [00:03<00:00,  8.18it/s, loss=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 1.8852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 24: 100%|██████████| 25/25 [00:03<00:00,  8.22it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 1.8702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 25: 100%|██████████| 25/25 [00:03<00:00,  8.25it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 1.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 26: 100%|██████████| 25/25 [00:03<00:00,  8.20it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 1.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 27: 100%|██████████| 25/25 [00:03<00:00,  8.19it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 1.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 28: 100%|██████████| 25/25 [00:03<00:00,  8.21it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 1.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 29: 100%|██████████| 25/25 [00:03<00:00,  8.14it/s, loss=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 1.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 30: 100%|██████████| 25/25 [00:03<00:00,  8.20it/s, loss=1.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 1.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 31: 100%|██████████| 25/25 [00:03<00:00,  8.22it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss: 1.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 32: 100%|██████████| 25/25 [00:03<00:00,  8.16it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss: 1.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 33: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s, loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss: 1.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 34: 100%|██████████| 25/25 [00:03<00:00,  8.19it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss: 1.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 35: 100%|██████████| 25/25 [00:03<00:00,  8.27it/s, loss=1.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss: 1.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 36: 100%|██████████| 25/25 [00:03<00:00,  8.21it/s, loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss: 1.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 37: 100%|██████████| 25/25 [00:03<00:00,  8.27it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss: 1.8442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 38: 100%|██████████| 25/25 [00:03<00:00,  8.23it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss: 1.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 39: 100%|██████████| 25/25 [00:03<00:00,  8.17it/s, loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss: 1.8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 40: 100%|██████████| 25/25 [00:03<00:00,  8.18it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss: 1.8433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 41: 100%|██████████| 25/25 [00:03<00:00,  8.16it/s, loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss: 1.8423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 42: 100%|██████████| 25/25 [00:03<00:00,  8.25it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss: 1.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 43: 100%|██████████| 25/25 [00:03<00:00,  8.14it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss: 1.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 44: 100%|██████████| 25/25 [00:03<00:00,  8.18it/s, loss=1.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss: 1.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 45: 100%|██████████| 25/25 [00:03<00:00,  8.20it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss: 1.8373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 46: 100%|██████████| 25/25 [00:03<00:00,  8.17it/s, loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss: 1.8373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 47: 100%|██████████| 25/25 [00:03<00:00,  8.15it/s, loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss: 1.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 48: 100%|██████████| 25/25 [00:03<00:00,  8.15it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss: 1.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 49: 100%|██████████| 25/25 [00:03<00:00,  8.16it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss: 1.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 50: 100%|██████████| 25/25 [00:03<00:00,  8.13it/s, loss=1.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss: 1.8299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer (only last layer is trainable)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Fine-tuning loop\n",
    "model.train()\n",
    "num_epochs = 50  # since you're just adapting the head\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(kitti_loader, desc=f\"Fine-tuning Epoch {epoch+1}\")\n",
    "\n",
    "    for images, masks in loop:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        images = T.Normalize(mean=[0.5]*3, std=[0.5]*3)(images)\n",
    "\n",
    "        out, _, _ = model(images)\n",
    "        loss = criterion(out, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(kitti_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378505f",
   "metadata": {},
   "source": [
    "### Evaluating on KITTI Dataset after Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59c56eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating mIoU: 100%|██████████| 25/25 [00:03<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean IoU over validation set: 0.0446\n",
      "KITTI mIoU: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "miou_metric = MulticlassJaccardIndex(num_classes=34, ignore_index=255).to(device)\n",
    "\n",
    "def evaluate_kitti(model, loader, device):\n",
    "    model.eval()\n",
    "    miou_metric.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loop = tqdm(loader, desc=\"Evaluating mIoU\")\n",
    "\n",
    "        for step, (images, masks) in enumerate(val_loop):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            images = T.Normalize(mean=[0.5]*3, std=[0.5]*3)(images)\n",
    "\n",
    "            outputs, _, _ = model(images) \n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            miou_metric.update(preds, masks)\n",
    "\n",
    "    mean_iou = miou_metric.compute().item()\n",
    "    print(f\"\\nMean IoU over validation set: {mean_iou:.4f}\")\n",
    "    return mean_iou\n",
    "\n",
    "val_miou = evaluate_kitti(model, kitti_loader, device)\n",
    "print(f\"KITTI mIoU: {val_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f45aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92594641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49321b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_losses, val_ious, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b4a485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss and mIoU\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_ious, label=\"Val mIoU\", color=\"green\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mIoU\")\n",
    "plt.title(\"Validation mIoU\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aacd102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot train loss (has value every epoch)\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "\n",
    "# Prepare filtered val loss and x-ticks\n",
    "val_epochs = [i for i, v in enumerate(val_losses) if v is not None]\n",
    "val_values = [v for v in val_losses if v is not None]\n",
    "\n",
    "plt.plot(val_epochs, val_values, label='Validation Loss', marker='o')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig('loss_plot.png')\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04d52b",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
